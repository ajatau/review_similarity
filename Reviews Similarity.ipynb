{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Amazon Food Reviews\n",
        "\n",
        "Download link: https://snap.stanford.edu/data/web-FineFoods.html\n",
        "\n",
        "This dataset consists of reviews of fine foods from Amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plaintext review. We also have reviews from all other Amazon categories.\n",
        "\n",
        "**Dataset Statistics**\n",
        "- Number of reviews: 568,454\n",
        "- Number of users: 256,059\n",
        "- Number of products: 74,258\n",
        "- Users with > 50 reviews: 260\n",
        "- Median no. of words per review: 56\n",
        "- Timespan: Oct 1999-Oct 2012"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import datetime\n",
        "from sklearn.feature_extraction import stop_words\n",
        "\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "sns.set(style='whitegrid', color_codes=True)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part I: Dataframe and Dictionary Setup"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "food_reviews_filepath = os.path.expanduser('~/Downloads/Stears/finefoods.txt') \n",
        "\n",
        "with open(food_reviews_filepath,encoding=\"latin-1\") as f:\n",
        "    food_reviews_raw = f.read()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "fields = ['product/productId', 'review/userId', 'review/profileName', 'review/helpfulness',\n",
        "           'review/score', 'review/time', 'review/summary', 'review/text']\n",
        "\n",
        "df = pd.DataFrame([{line.split(': ')[0]:''.join(line.split(': ')[1]) \n",
        "                    for line in review.split('\\n') if line.split(': ')[0] in fields}\n",
        "                    for review in list(filter(None, food_reviews_raw.split('\\n\\n')))]) # Remove empty string created by the split.\n",
        "\n",
        "df.columns = ['product_id', 'helpfulness', 'profile_name', 'score', 'summary', 'text', 'time', 'user_id']\n",
        "reordered_columns = ['product_id', 'user_id', 'profile_name', 'helpfulness', 'score', 'time', 'summary', 'text']\n",
        "df = df[reordered_columns]"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df['norm_text'] = df.text.map(lambda x: re.sub(r'<a href=\\S+>', '', x))\n",
        "df['norm_text'] = df.norm_text.map(lambda x: x.replace('</a>', '')) \n",
        "df['norm_text'] = df.norm_text.map(lambda x: x.replace('<br />', ' ')) \n",
        "df['norm_text'] = df.norm_text.map(lambda x: x.replace('&quot;', '')) \n",
        "df['norm_text'] = df.norm_text.map(lambda x: x.replace('&amp;', 'and'))\n",
        "df['norm_text'] = df.norm_text.map(lambda x: x.lower()) \n",
        "df['norm_text'] = df.norm_text.map(lambda x: x.translate(str.maketrans('', '', string.punctuation))) \n",
        "df['norm_text'] = df.norm_text.map(lambda x: x.replace('  ', ' '))"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates(subset=['text'], keep=False)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 334656 entries, 0 to 568453\n",
            "Data columns (total 9 columns):\n",
            "product_id      334656 non-null object\n",
            "user_id         334656 non-null object\n",
            "profile_name    334656 non-null object\n",
            "helpfulness     334656 non-null object\n",
            "score           334656 non-null object\n",
            "time            334656 non-null object\n",
            "summary         334656 non-null object\n",
            "text            334656 non-null object\n",
            "norm_text       334656 non-null object\n",
            "dtypes: object(9)\n",
            "memory usage: 25.5+ MB\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reviews from Target Product Categories**\n",
        "\nLoad 2000 reviews of coffee, tea, chocolate, and pet food."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "product_indexes_df = pd.read_csv('product indexes.csv', index_col=0)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "coffee_df = df[df.index.isin(product_indexes_df.coffee)]\n",
        "tea_df = df[df.index.isin(product_indexes_df.tea)]\n",
        "chocolate_df = df[df.index.isin(product_indexes_df.chocolate)]\n",
        "petfood_df = df[df.index.isin(product_indexes_df.petfood)]"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(coffee_df), len(tea_df), len(chocolate_df), len(petfood_df))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000 2000 2000 2000\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print('HOORAY! I AM ALL SET UP AND READY TO COMPLETE THIS ASSEMMENT BY WEDNESDAY AT 11.59PM GMT!')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dataframe of random 2,000 reviews \n",
        "random_df = df.sample(n=2000)\n"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = np.array(df['norm_text'])"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a text file with all the reviews.\n",
        "with open('fasttext-embedding-train.txt', 'w', encoding='utf-8') as target:\n",
        "    for review in reviews:\n",
        "        target.write(review.strip())"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing fasttext and training a model on the text file created above using the skipgram method\n",
        "\n",
        "import fastText as ft\n",
        "# Skipgram model :\n",
        "model = ft.train_unsupervised('fasttext-embedding-train.txt', model='skipgram')"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the wordvector for 'the' from the model built\n",
        "\nmodel.get_word_vector(\"the\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": [
              "array([-0.13178036,  0.15103085, -0.09445549,  0.08752053, -0.10314239,\n",
              "       -0.03947441, -0.17363147,  0.03591475,  0.12136652, -0.11854628,\n",
              "        0.0938407 ,  0.0889246 , -0.05785259,  0.03846101, -0.31799814,\n",
              "        0.0712427 ,  0.07776776, -0.12263791, -0.00141949, -0.20832673,\n",
              "        0.10824981,  0.28727096, -0.2985838 , -0.23388836, -0.04605399,\n",
              "       -0.11447003,  0.24057436, -0.4701844 ,  0.0008751 , -0.0604997 ,\n",
              "       -0.11415392,  0.13534136,  0.21330446, -0.07566531, -0.15537713,\n",
              "       -0.24764854,  0.08898085, -0.07422888, -0.02914689,  0.4069497 ,\n",
              "       -0.05612462,  0.09801798, -0.09631327,  0.08725455, -0.07992944,\n",
              "        0.17693417,  0.06491788, -0.02639729,  0.06743106, -0.05741929,\n",
              "       -0.17996565,  0.01780565,  0.0575686 ,  0.2427695 ,  0.02689069,\n",
              "       -0.01879577, -0.1529363 , -0.01951067,  0.08162269,  0.08273382,\n",
              "        0.07461046,  0.2154608 ,  0.16531011,  0.21018226, -0.00971015,\n",
              "       -0.1895928 ,  0.05623697,  0.1672068 , -0.26963466, -0.04158632,\n",
              "       -0.06735165, -0.21789642, -0.11211355,  0.37464663,  0.03415449,\n",
              "        0.24146762, -0.07845893, -0.14706872, -0.04656641, -0.12869582,\n",
              "        0.10228396, -0.0238638 ,  0.18243273, -0.06321216, -0.14974308,\n",
              "       -0.414555  , -0.14099462, -0.12755159,  0.19996567, -0.02641804,\n",
              "        0.09702698,  0.0450383 ,  0.15331344,  0.10986612, -0.2078938 ,\n",
              "       -0.13659869, -0.08848855, -0.03659305, -0.17805244,  0.04931789],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the dataframe for each of the product reviews to list\n",
        "\n\n",
        "full_reviews = df['norm_text'].tolist()\n",
        "coffee_reviews = coffee_df['norm_text'].tolist()\n",
        "tea_reviews = tea_df['norm_text'].tolist()\n",
        "chocolate_reviews = chocolate_df['norm_text'].tolist()\n",
        "petfood_reviews = petfood_df['norm_text'].tolist()\n",
        "random_reviews = random_df['norm_text'].tolist()\n"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting stop words to a variable and define function to remove stopwords from text passed to it\n",
        "\n",
        "stop_list = set(stop_words.ENGLISH_STOP_WORDS)\n",
        "\n",
        "def remove_stop_word(text):\n",
        "    return [word for word in text.split() if word not in stop_list]\n",
        "    "
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop words for each of the product review dataframes\n",
        "\n",
        "full_reviews = [remove_stop_word(x) for x in full_reviews]\n",
        "coffee_reviews = [remove_stop_word(x) for x in coffee_reviews]\n",
        "tea_reviews = [remove_stop_word(x) for x in tea_reviews]\n",
        "chocolate_reviews = [remove_stop_word(x) for x in chocolate_reviews]\n",
        "petfood_reviews = [remove_stop_word(x) for x in petfood_reviews]\n",
        "random_reviews = [remove_stop_word(x) for x in random_reviews]"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing CountVectorizer from sklearn and defining a function to create a dictionary for list passed to it \n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n\n",
        "def dictionary_creator(review):\n",
        "    vectorizer = CountVectorizer()\n",
        "    vectorizer.fit_transform([x for y in review for x in y])\n",
        "    return vectorizer.vocabulary_"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a list of all reviews list and passing them through a loop to create dictionaries for each product review\n",
        "\n",
        "reviews_list = [full_reviews,coffee_reviews,tea_reviews,chocolate_reviews,petfood_reviews,random_reviews]\n",
        "\n",
        "full_review_dict = dict()\n",
        "coffee_review_dict = dict()\n",
        "tea_review_dict = dict()\n",
        "chocolate_review_dict = dict()\n",
        "petfood_review_dict = dict()\n",
        "random_review_dict = dict()\n",
        "\n",
        "dict_list = [full_review_dict,coffee_review_dict,tea_review_dict,chocolate_review_dict,petfood_review_dict,random_review_dict]\n",
        "\n\n",
        "for review,dic in zip(reviews_list,dict_list):\n",
        "    \n",
        "    dictionary = dictionary_creator(review)\n",
        "    dic.update(dictionary)"
      ],
      "outputs": [],
      "execution_count": 70,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "max(petfood_review_dict.values())"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 120,
          "data": {
            "text/plain": [
              "10775"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 120,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part II"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to take in 2 sets and calculate the jaccard similarity\n",
        "\n",
        "def jaccard_similarity(query, document):\n",
        "    intersection = set(query).intersection(set(document))\n",
        "    union = set(query).union(set(document))\n",
        "    return len(intersection)/len(union)"
      ],
      "outputs": [],
      "execution_count": 77,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Jaccard similarity of coffee to tea {}'.format(jaccard_similarity(coffee_review_dict,tea_review_dict)))\n",
        "print ('Jaccard similarity of coffee to chocolate {}'.format(jaccard_similarity(coffee_review_dict,chocolate_review_dict)))\n",
        "print('Jaccard similarity of coffee to petfood {}'.format(jaccard_similarity(coffee_review_dict,petfood_review_dict)))\n",
        "print('Jaccard similarity of coffee to random {}'.format(jaccard_similarity(coffee_review_dict,random_review_dict)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard similarity of coffee to tea 0.3152220784821044\n",
            "Jaccard similarity of coffee to chocolate 0.3079188757047884\n",
            "Jaccard similarity of coffee to petfood 0.2528184892897407\n",
            "Jaccard similarity of coffee to random 0.3081225872528165\n"
          ]
        }
      ],
      "execution_count": 88,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print('Jaccard similarity of coffee to coffee {}'.format(jaccard_similarity(coffee_review_dict,coffee_review_dict)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard similarity of coffee to coffee 1.0\n"
          ]
        }
      ],
      "execution_count": 89,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Rankings\n",
        " Rankings in descending order:\n",
        "\n\n",
        "|   Review  | Jaccard Similarity |\n",
        "|:---------:|:------------------:|\n",
        "|   Coffee  |         1.0        |\n",
        "|    Tea    |        0.315       |\n",
        "|   Random  |        0.308       |\n",
        "| Chocolate |        0.307       |\n",
        "|  Petfood  |        0.252       |"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        " - The most similar product is Tea\n",
        " - The least similar product is Petfood"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fasttext Similarity"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step I"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to get vectors of each dataframe passed to it\n",
        "\n\n",
        "def get_vector(review_df,name):\n",
        "    \n",
        "    # Convert each review to an array\n",
        "    reviews = np.array(review_df['norm_text'])\n",
        "    \n",
        "    # Write the text to a file with the name input\n",
        "    with open('{}_fasttext-embedding-train.txt'.format(name), 'w', encoding='utf-8') as target:\n",
        "        for review in reviews:\n",
        "            target.write(review.strip())\n",
        "    \n",
        "    # Open the file and read all text and assign to variable\n",
        "    with open('{}_fasttext-embedding-train.txt'.format(name)) as f:\n",
        "        text = f.read()\n",
        "        \n",
        "    # get the word vector for the text \n",
        "    return model.get_word_vector(text)"
      ],
      "outputs": [],
      "execution_count": 102,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the word vector for all reviews \n",
        "\n",
        "coffee_vector = get_vector(coffee_df,'coffee')\n",
        "chocolate_vector = get_vector(chocolate_df,'chocolate')\n",
        "tea_vector = get_vector(tea_df,'tea')\n",
        "petfood_vector = get_vector(petfood_df,'petfood')"
      ],
      "outputs": [],
      "execution_count": 105,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "random_vector= get_vector(random_df,'random')"
      ],
      "outputs": [],
      "execution_count": 108,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the cosine similarity after importing scipy \n",
        "\n",
        "from scipy import spatial\n",
        "def fasttext_similarity(vector1,vector2):\n",
        "    \n",
        "    # spatial.distance.cosine computes the distance, and not the similarity. \n",
        "    #So, you must subtract the value from 1 to get the similarity\n",
        "    \n",
        "    return 1 - spatial.distance.cosine(vector1, vector2)"
      ],
      "outputs": [],
      "execution_count": 106,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Cosine similarity of coffee to coffee {}'.format(fasttext_similarity(coffee_vector,coffee_vector)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity of coffee to coffee 1.0\n"
          ]
        }
      ],
      "execution_count": 110,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Cosine similarity of coffee to tea {}'.format(fasttext_similarity(coffee_vector,tea_vector)))\n",
        "print ('Cosine similarity of coffee to chocolate {}'.format(fasttext_similarity(coffee_vector,chocolate_vector)))\n",
        "print('Cosine similarity of coffee to petfood {}'.format(fasttext_similarity(coffee_vector,petfood_vector)))\n",
        "print('Cosine similarity of coffee to random {}'.format(fasttext_similarity(coffee_vector,random_vector)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity of coffee to tea 0.9665085077285767\n",
            "Cosine similarity of coffee to chocolate 0.9321482181549072\n",
            "Cosine similarity of coffee to petfood 0.8971323370933533\n",
            "Cosine similarity of coffee to random 0.9554436802864075\n"
          ]
        }
      ],
      "execution_count": 109,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scores for the jaccard similarity are on a lower scale while the scores for the cosine similarity are higher. As shown in the table below, Cosine similarirty captures the similarity between coffee and tea better.\n",
        "\n",
        "| Review    | Cosine Similarity(with Coffee) | Jaccard Similarity(with coffee) |\n",
        "|-----------|--------------------------------|---------------------------------|\n",
        "| Coffee    | 1.0                            | 1.0                             |\n",
        "| Chocolate | 0.932                          | 0.307                           |\n",
        "| Tea       | 0.966                          | 0.315                           |\n",
        "| Random    | 0.955                          | 0.308                           |\n",
        "| Petfood   | 0.897                          | 0.252                           |"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The random reviews has a high similarity in both jaccard and cosine, probably because it contains coffee, chocolate and tea reviews."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 3"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "This assumption depends on the content of the 400 word review. If it is more detailed than the 100 word review then it could have more information.\n",
        "\nSome extra normalisation could be added to the reviews such as expanding abbreviations, text canonicalization."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the frequency of words in the dictionaries they are all equally indicative."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bonus"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df['time'] = df['time'].astype(int)"
      ],
      "outputs": [],
      "execution_count": 128,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "bonus_df = df[df['time'].between(939340800,1351209600)]\n",
        "len(bonus_df)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 127,
          "data": {
            "text/plain": [
              "334656"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 127,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}